
<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>Doppelganger++</title>

  <!-- Google tag (gtag.js)
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-1EWGMC7JTK"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-1EWGMC7JTK');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="data:image/svg+xml,
    <svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22>
      <text y=%22.9em%22 font-size=%2290%22>üèõÔ∏è</text>
    </svg>"
  >

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script> -->
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="publication-title is-size-1 publication-title">Doppelgangers++: Improved Visual Disambiguation with Geometric 3D Features</h1>

          <!-- <div class="is-size-5 publication-venue">ECCV 2024</div> -->

          <div class="is-size-5 publication-authors">
            <span class="author-block">
                Anonymous Authors
            </span>
          </div>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./static/images/teaser.png"
        class="interpolation-image"
        alt="Interpolate start reference image."/>
      <h2 class="subtitle has-text-centered">
        Visual aliasing, or doppelgangers, poses severe challenges to 3D reconstruction. We propose Doppelganger++, an enhanced pairwise image
        classifier that excels in visual disambiguation across diverse and challenging scenes. (Top) We seamlessly integrate Doppelganger++ into SfM, successfully
        disambiguating each scene. (Middle) Compared to prior work (which we refer to as DG-OG [3]), Doppelgangers++ is more robust for everyday scenes,
        showing improved accuracy and robustness. We show pairs that DG-OG classifies incorrectly and ours gets correct. (Bottom) Our new VisymScenes dataset,
        featuring complex daily scenes, is particularly challenging for COLMAP and DG-OG, but our method can achieve correct and complete reconstructions.
      </h2>
    </div>


  </div>
</section>


<section class="section hero is-light">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Accurate 3D reconstruction is frequently hindered by visual aliasing, where visually similar but distinct surfaces (aka, doppelgangers), 
            are incorrectly matched. These spurious matches distort the structure-from-motion (SfM) process, leading to misplaced model elements and reduced accuracy. 
            Prior efforts addressed this with CNN classifiers trained on curated datasets, but these approaches struggle to generalize across diverse real-world scenes and can require extensive parameter tuning. 
            In this work, we present Doppelgangers++, a method to enhance doppelganger detection and improve 3D reconstruction accuracy. 
            Our contributions include a diversified training dataset that incorporates geo-tagged images from everyday scenes to expand robustness beyond landmark-based datasets. 
            We further propose a Transformer-based classifier that leverages 3D-aware features from the MASt3R model, achieving superior precision and recall across both in-domain and out-of-domain tests. 
            Doppelgangers++ integrates seamlessly into standard SfM and MASt3R-SfM pipelines, offering efficiency and adaptability across varied scenes. 
            To evaluate SfM accuracy, we introduce an automated, geotag-based method for validating reconstructed models, eliminating the need for manual inspection. 
            Through extensive experiments, we demonstrate that Doppelgangers++ significantly enhances pairwise visual disambiguation and improves 3D reconstruction quality in complex and diverse scenarios.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <div class="columns is-centered has-text-centered">
        <h2 class="title is-3">The VisymScenes Dataset</h2>
      </div>
          <p>
            This new dataset includes residential areas, landmarks, historical sites, business districts, and more.
            Here are 4 examples. The top row shows subsets of images captured within each site. The bottom row displays pairs of visually
            similar but geographically distinct images from each site along with their recorded geolocations on a map. These examples demonstrate that
            doppelganger issues are prevalent in everyday scenes, presenting significant challenges for reliable 3D reconstruction and image matching.
          </p>
          <img src="./static/images/visym_example.png"/>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <div class="columns is-centered has-text-centered">
        <h2 class="title is-3">Improved Doppelganger Classifier</h2>
      </div>
          <p>
            Model design. (Left) Given an image pair, we first create a symmetrized version of the pair and feed it into the frozen MASt3R
            model. Multi-layer features are extracted from each decoder branch, concatenated, and fed into two learnable doppelganger classification
            heads. Each head generates predictions supervised by cross-entropy loss. 
            (Right) We use multi-layer decoder features and a Transformer-based classifier head for doppelganger prediction.

          </p>
          <img src="./static/images/model.png"/>
      </div>
    </div>
  </div>
</section>



<!-- <section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <div class="columns is-centered has-text-centered">
        <h2 class="title is-3">Dataset Layout</h2>
      </div>
          <p>
            layout: depends on how joseph you decide to organize the directories and subdirectories? e.g. grouped by first two letters 

          </p>
      </div>
    </div>
  </div>
</section> -->


<section class="section" style="margin-bottom: 10px; padding-bottom: 0px;">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <div class="columns is-centered has-text-centered">
        <h2 class="title is-3">Evaluating Doppelganger correction in SfM</h2>
      </div>
          <p>
            There is currently no reliable benchmarking method for evaluating the accuracy and correctness of SfM reconstruc293 tions specifically in terms of how well they address the doppelganger issue.
            We propose to leverage mapping sites like Mapillary, which provide images with location metadata that can serve as probes for validating a 3D model.
            We first collect sequences of geo-tagged Mapillary images around the target location and register them to the SfM model. Then, we
            use RANSAC to align the registered cameras and their geolocations.
            The inlier ratio is computed as an indicator of model accuracy. (Bottom) In the model corrupted by doppelganger pairs, the registered
            cameras all collapse to one side. We see that the camera poses
            estimated with COLMAP (right, in red) do not align well with the
            geotags (green), leading to a low inlier ratio, but our method leads
            to a much closer alignmen
           
          </p>
          <img src="./static/images/sfm_evaluation.png"/>
      </div>
    </div>
  </div>
</section>


<!-- <section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">

      <div class="column">
        <div class="content">
          <h2 class="title is-4">Evaluation on Pairwise Disambiguation</h2>
          <img src="./static/images/pairwise_tab.png"/>
          <figcaption> We evaluate DG-OG and our method trained on DG only and DG+VisymScenes (two numbers per cell) on three test sets. 
            Both DG-OG and ours benefit from dataset expansion, whereas ours gained more generalizability on out-of-domain test set (Mapillary) after
            training on both. Our classifier constantly demonstrates better precision, recall across all settings.</figcaption>
        </div>
      </div>
    </div>
  </div>
</section> -->

<!-- 
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <div class="columns is-centered has-text-centered">
        <h2 class="title is-4">Evaluation</h2>
      </div>
          <p>
            We evaluate on MegaScenes‚Äô test set, which consists of in-the-wild scenes from Internet photos. Here, we show comparisons between four models. 1. SD-inpainting: A Stable Diffusion inpainting model without any finetuning. 2. ZeroNVS (released): The ZeroNVS released checkpoint. 3. ZeroNVS (MS): ZeroNVS finetuned on MegaScenes. 4. Ours: Finetuned from ZeroNVS on MegaScenes, and conditioned on both the extrinsic matrices and the warped images.

            See the paper for more evaluations and baselines. 

          </p>

          <img src="./static/images/nvs/qual_results.png" style="margin-top: 20px;"/>
          <img src="./static/images/nvs/quant_results.png" style="margin-top: 20px;" />
      </div>
    </div>
  </div>
</section> -->






<footer class="footer">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is borrowed from <a href="https://nerfies.github.io/">Nerfies</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
